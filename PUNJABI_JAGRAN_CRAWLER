#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import re
import socket
import xlsxwriter
import urllib.request
from bs4 import BeautifulSoup
from urllib.parse import quote
from urllib.request import urlopen
from urllib.request import Request, URLError

'''Initialize Punjabi Tribune newspaper URL'''
req = Request('https://punjabi.jagran.com/', headers={'User-Agent': 'Mozilla/5.0'})
try:
    req.selector.encode('ascii')
except UnicodeEncodeError:
    req.selector = quote(req.selector)

try:
    response = urllib.request.urlopen(req, timeout=30)
    html = response.read().decode('utf-8')
except socket.timeout:
    pass
except URLError:
    pass
punjabi_jagran_genre_dictionary = {}
workbook = ''
row = 1
col = 0
file_number = 0

def get_url_page_paragraph_text(url):
    '''
    Function generates the paragaph text from the News URL provided
    as the parameter
    :param url: URL of the page
    :return:
    '''
    genre_page = Request(url, headers={'User-Agent': 'Mozilla/5.0'})
    try:
        genre_page.selector.encode('ascii')
    except UnicodeEncodeError:
        genre_page.selector = quote(genre_page.selector)
    try:
        page_response = urllib.request.urlopen(genre_page, timeout=30)
        page = page_response.read().decode('utf-8')
        parser = BeautifulSoup(page, "html.parser")
        for h1_tag in parser.findAll('div', attrs={'class': 'articleHd'}):
            print(h1_tag.h1.text)
            date_text = h1_tag.span.text
            print(date_text)
            # Regular expression group extraction pattern
            pattern = r', ([0-9]+) ([\w]*) ([0-9]+)'
            date = re.search(pattern, date_text).group(1)
            month = re.search(pattern, date_text).group(2)
            year = re.search(pattern, date_text).group(3)
            print("Date: ", date, " Month: ", month, " Year: ", year)

            parsed_text = parser.find('div', attrs={'class': 'articleBody'}).findAll(['p', 'span'])
            news_article = ''
            for element in parsed_text:
                news_article += ''.join(element.findAll(text=True))
        print(news_article)
    except socket.timeout:
        pass
    except URLError:
        pass
    except socket.error:
        pass


def get_page_title_and_link(url):
    '''
    This function extracts the page title and URL to the news
    item and send the URL to the get_url_page_paragraph_text function
    to extract the paragraph text

    :param url: Page URL
    '''
    global file_number
    genre_page = Request(url, headers={'User-Agent': 'Mozilla/5.0'})
    try:
        genre_page.selector.encode('ascii')
    except UnicodeEncodeError:
        genre_page.selector = quote(genre_page.selector)
    try:
        page_response = urllib.request.urlopen(genre_page, timeout=30)
        page = page_response.read().decode('utf-8')
        parser = BeautifulSoup(page, "html.parser")
        for ul in parser.findAll('ul', attrs={'class': 'topicList'}):
            extension = ul.find('a')['href']
            page_url = "https://punjabi.jagran.com" + extension
            print(page_url)
            get_url_page_paragraph_text(page_url)
    except socket.timeout:
        pass
    except URLError:
        pass
    except socket.error:
        pass

def get_page_links(url, genre_name, start_num, end_num):
    website_url = "https://punjabi.jagran.com/"
    jagran_page_link = website_url + genre_name +"-news-punjabi-page"
    for i in range(start_num, end_num):
        link = jagran_page_link + str(i) + ".html"
        get_page_title_and_link(link)
        #print(link)

def main():
    # make_directory(folder)
    # create_excel_sheet("sports")
    '''
        Genres = agriculture, world, entertainment, education, technology, editorial,
        nri, business, religion, national
    '''
    start = 2  # Start Page Number
    end = 62  # Last Page Number in genre
    link = "https://punjabi.jagran.com/sports-news-punjabi.html"
    genre = "sports" # Change the genre over here from the presentend list
    get_page_links(link, genre, start, end)

if __name__ == '__main__':
    main()